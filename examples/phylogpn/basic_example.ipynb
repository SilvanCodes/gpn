{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/accounts/projects/yss/carlos_albors/gpn/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/accounts/projects/yss/carlos_albors/gpn/venv/lib/python3.12/site-packages/transformers/utils/hub.py:106: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "A new version of the following files was downloaded from https://huggingface.co/songlab/PhyloGPN:\n",
      "- tokenization_phylogpn.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/songlab/PhyloGPN:\n",
      "- configuration_phylogpn.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/songlab/PhyloGPN:\n",
      "- modeling_phylogpn.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from gpn.phylogpn import model, tokenizer # Wrapper around HuggingFace\n",
    "\n",
    "# Example data\n",
    "seqs = [\n",
    "    \"TATAAA\",\n",
    "    \"GGCCAATCT\",\n",
    "    \"CACGTG\",\n",
    "    \"AGGTCACGT\",\n",
    "    \"GCCAGCC\",\n",
    "    \"GGGGATTTCC\"\n",
    "]\n",
    "\n",
    "# Output length is input length minus 480 (the receptive field size minus 1)\n",
    "pad_token = tokenizer.pad_token\n",
    "pad_size = 481 // 2\n",
    "pad_sequence = lambda seq: pad_token * pad_size + seq + pad_token * pad_size\n",
    "padded_seqs = [pad_sequence(seq) for seq in seqs]\n",
    "input_tensor = tokenizer(padded_seqs, return_tensors=\"pt\", padding=True)[\"input_ids\"]\n",
    "\n",
    "with torch.no_grad():\n",
    "    padded_embeddings = model.get_embeddings(input_tensor)\n",
    "    padded_logits = model(input_tensor) # These are log rate parameters for the F81 model\n",
    "\n",
    "embeddings = []\n",
    "logits = []\n",
    "\n",
    "for i in range(len(seqs)):\n",
    "    length = len(seqs[i])\n",
    "    embeddings.append(padded_embeddings[i, :length])\n",
    "    logits.append({})\n",
    "\n",
    "    for k in \"ACGT\":\n",
    "        logits[-1][k] = padded_logits[k][i, :length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2399,  0.2717,  0.1193,  ..., -0.2694,  1.2095, -0.8143],\n",
       "        [-0.3725,  1.2785, -0.0264,  ..., -0.5638, -0.1288, -1.1086],\n",
       "        [-0.7089,  0.8101, -1.5966,  ..., -0.4742,  1.5401, -0.8086],\n",
       "        [-0.6684,  1.1999, -1.6881,  ...,  0.0269, -0.1773,  0.2568],\n",
       "        [-0.1105,  0.2217, -0.3428,  ..., -0.4531,  1.1346, -0.8851],\n",
       "        [-0.8363,  1.2306,  0.3084,  ..., -0.7149,  0.5221,  0.4968]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `embeddings` is a list of tensors, one per item in the batch, each containing embeddings for each position in the sequence\n",
    "embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': tensor([ 0.3503,  0.1109,  0.5503, -0.1649,  0.6182,  0.1694]),\n",
       " 'C': tensor([-0.0261,  0.3540, -0.3431,  0.5716,  0.4910,  0.3965]),\n",
       " 'G': tensor([0.4168, 0.4671, 0.3895, 0.1255, 0.1161, 0.3556]),\n",
       " 'T': tensor([-0.2667,  0.0614, -0.2464,  0.5956, -0.1491, -0.1738])}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `logits` is a list of dictionaries, one per item in the batch, each containing the log rate parameters for the F81 model\n",
    "logits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/tmp/ipykernel_2657358/2882572435.py\u001b[0m(8)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      6 \u001b[0;31m    \u001b[0mlogit_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlogit_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m\"ACGT\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      7 \u001b[0;31m    \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m----> 8 \u001b[0;31m    \u001b[0mlikelihood_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogit_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      9 \u001b[0;31m    \u001b[0mlikelihood_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlikelihood_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ACGT\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     10 \u001b[0;31m    \u001b[0mlikelihood_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlikelihood_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 4])\n",
      "torch.Size([6])\n",
      "tensor([[ 0.3503, -0.0261,  0.4168, -0.2667],\n",
      "        [ 0.1109,  0.3540,  0.4671,  0.0614],\n",
      "        [ 0.5503, -0.3431,  0.3895, -0.2464],\n",
      "        [-0.1649,  0.5716,  0.1255,  0.5956],\n",
      "        [ 0.6182,  0.4910,  0.1161, -0.1491],\n",
      "        [ 0.1694,  0.3965,  0.3556, -0.1738]])\n",
      "tensor([[ 0.3503,  0.1109,  0.5503, -0.1649,  0.6182,  0.1694],\n",
      "        [-0.0261,  0.3540, -0.3431,  0.5716,  0.4910,  0.3965],\n",
      "        [ 0.4168,  0.4671,  0.3895,  0.1255,  0.1161,  0.3556],\n",
      "        [-0.2667,  0.0614, -0.2464,  0.5956, -0.1491, -0.1738]])\n",
      "tensor([[ 0.3503,  0.1109,  0.5503, -0.1649,  0.6182,  0.1694],\n",
      "        [-0.0261,  0.3540, -0.3431,  0.5716,  0.4910,  0.3965],\n",
      "        [ 0.4168,  0.4671,  0.3895,  0.1255,  0.1161,  0.3556],\n",
      "        [-0.2667,  0.0614, -0.2464,  0.5956, -0.1491, -0.1738]])\n",
      "tensor([[ 0.3503,  0.1109,  0.5503, -0.1649,  0.6182,  0.1694],\n",
      "        [-0.0261,  0.3540, -0.3431,  0.5716,  0.4910,  0.3965],\n",
      "        [ 0.4168,  0.4671,  0.3895,  0.1255,  0.1161,  0.3556],\n",
      "        [-0.2667,  0.0614, -0.2464,  0.5956, -0.1491, -0.1738]])\n",
      "tensor([[ 0.3503,  0.1109,  0.5503, -0.1649,  0.6182,  0.1694],\n",
      "        [-0.0261,  0.3540, -0.3431,  0.5716,  0.4910,  0.3965],\n",
      "        [ 0.4168,  0.4671,  0.3895,  0.1255,  0.1161,  0.3556],\n",
      "        [-0.2667,  0.0614, -0.2464,  0.5956, -0.1491, -0.1738]])\n"
     ]
    }
   ],
   "source": [
    "# Get likelihoods\n",
    "\n",
    "likelihood_list = []\n",
    "\n",
    "for logit_dict in logits:\n",
    "    logit_tensor = torch.stack([logit_dict[k] for k in \"ACGT\"], dim=1)\n",
    "    likelihood_tensor = torch.softmax(logit_tensor, dim=1)\n",
    "    likelihood_dict = {k: likelihood_tensor[i] for i, k in enumerate(\"ACGT\")}\n",
    "    likelihood_list.append(likelihood_dict)\n",
    "\n",
    "likelihood_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.2926)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Log likelihood ratios are used to score whether a substitution is more likely under one model than another\n",
    "# For example, the log likelihood ratio of a C to T substitution at position 2 in the first sequence is:\n",
    "logits[0][\"T\"][1] - logits[0][\"C\"][1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
